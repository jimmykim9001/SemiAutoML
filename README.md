# To-Do
- [ ] Linear Models
    - [ ] Box-Cox Transformations, generating Y (pg 324)
    - [ ] Test for Heteroskedasticity (pg 329)
    - [ ] Variable Selection (pg 359)
    - [ ] Ridge Regression/LASSO
    - [ ] Generalized Linear Models + Logistic Regression
    - [ ] Model Selection Criteria (Ch. 22)
- [ ] Stat 154
    - [ ] PLSR
    - [ ] KNN/Kernels
    - [ ] Discriminant Analysis
    - [ ] Hierarchal Clustering + Clustering
    - [ ] Random Forests
- [ ] Deep Learning w. Tensorflow or PyTorch
- [ ] Data pipeline (k-fold, bagging, etc.)
- [ ] implement NestedCV (for all of model selection)

Prioritize LASSO (for variable selection), and model Selection
Then everything in Stat154 you think is interesting

- [ ] Learn about
    - [x] SVM/SVC
    - [ ] Boosting
    - [ ] Perceptron

Idea:
    1. Cross-validate for hyper-parameters, parameters, etc.
    2. Then try bagging/boosting 

LDA ESL pg 439

Create correlation matrix for inputs
Bayesian hyperparameter tuning
